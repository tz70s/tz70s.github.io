<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on tz70s</title>
    <link>https://tz70s.github.io/posts/</link>
    <description>Recent content in Posts on tz70s</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Tue, 14 May 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://tz70s.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Hacking a Small Size OSS Compiler</title>
      <link>https://tz70s.github.io/posts/hacking-small-size-oss-compiler/</link>
      <pubDate>Tue, 14 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tz70s.github.io/posts/hacking-small-size-oss-compiler/</guid>
      <description>Compiler is a well-known complex software to build, but also plays a significant role on computer science history and attracts many programmers to explore the mystery. Both of theory foundation and engineering of compiler construction is hard, and I&amp;rsquo;m not an expert (even not a compiler engineer) at all. However, in this post, I would like to show my experience to hacking PureScript compiler.
Strictly speaking, this is a transpiler instead of machine code generation.</description>
    </item>
    
    <item>
      <title>Reactive Programming - Revisiting Abstraction</title>
      <link>https://tz70s.github.io/posts/reactive-programming/</link>
      <pubDate>Tue, 12 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://tz70s.github.io/posts/reactive-programming/</guid>
      <description>Reactive Programming 在現代基於事件驅動程式設計及架構來講，根本上來講以去除副作用 (side-effect) 的 declarative 方式來建構事件的轉換及組合，可以有效降低在 concurrency 下的錯誤和增強組合性 (composability)。這衍伸在工業界如 ReactiveX (RxJava, RxJS, etc)、Reactive Stream Specification 或是如 Future 的建構都有其影子。
然而，他的定義從各個出處仍十分模糊且難以讓人理解，例如：
 Reactive Programming is a programming with asynchronous data stream. [1] Reactive programming is a declarative programming paradigm concerned with data streams and the propagation of change. [2] Reactive programming is a programming paradigm that is built around the notion of continuous time-varying values and propagation of change. [3]  在加上網路上基於各種感悟和體會的文章衍伸的不嚴謹考究，讓 Reactive Programming 逐漸成為 buzzword。</description>
    </item>
    
    <item>
      <title>Note - MBrace: Cloud Computing with Monads</title>
      <link>https://tz70s.github.io/posts/mbrace/</link>
      <pubDate>Fri, 07 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://tz70s.github.io/posts/mbrace/</guid>
      <description>Programming large-scale distributed systems is difficult and requires expert programmers orchestrating concurrent processes across various physical places (nodes), and potentially required to be scalable, resilient, etc. Choosing a well abstraction framework can reduce such efforts and make system performant and resilient.
For example,
 MapReduce Akka CloudHaskell[1] and HdpH[2]  However, problematics on MapReduce model: less expressive and not suitable for streaming, iterative and incremental algorithms. (NOTE: the motivation is less persuasive, IMHO)</description>
    </item>
    
    <item>
      <title>Google Summer of Code</title>
      <link>https://tz70s.github.io/posts/gsoc-2018/</link>
      <pubDate>Mon, 13 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://tz70s.github.io/posts/gsoc-2018/</guid>
      <description>This is a post to identify what I&amp;rsquo;ve done in Google Summer of Code 2018. It&amp;rsquo;s summarized in brief and non-technical, you can refer to more detail in the following links.
Links to what I&amp;rsquo;ve done:
 In-detail post about OpenWhisk performance improvement experiment. Main repo/branch for experiment. Invoker agent repo/branch for experiment. Extended multi-actions wrk peformance bench. Commits on OpenWhisk main repo during GSoC progress.  The Journey At first, my original GSoC proposal: OpenWhisk performance improvement - work stealing, priority-based scheduling on load balancer and direct connection for streaming capabilities.</description>
    </item>
    
    <item>
      <title>OpenWhisk Performance Improvement</title>
      <link>https://tz70s.github.io/posts/openwhisk-performance-improvement/</link>
      <pubDate>Tue, 24 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://tz70s.github.io/posts/openwhisk-performance-improvement/</guid>
      <description>OpenWhisk community is nowadays getting more consistent on the new design of architecture for performance improvement. The future architecture of OpenWhisk requires large internal breaking changes. To fill the gap from idea into smooth migration, there might be helpful if a mid ground exist to clear more issues. Hence, I&amp;rsquo;ve worked on prototyping performance improvement in real, but not that comprehensive though. However, hope this prototype hold a place for deeper discussion and discover all issues might meet in the future.</description>
    </item>
    
    <item>
      <title>Distributed Systems for Fun and Profit</title>
      <link>https://tz70s.github.io/posts/distributed-systems-for-fun-and-profit/</link>
      <pubDate>Wed, 07 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://tz70s.github.io/posts/distributed-systems-for-fun-and-profit/</guid>
      <description>Distributed Systems for Fun and Profit 是本分散式系統的書，短小精悍目標是涵蓋所有分散式系統的概念和點出一些關鍵的演算法，然後這是我的筆記。
Basics 基本電腦系統可以分為兩種 task 需要去完成
 storage computation  分散式系統的目標是要解決當我們系統 scale up 去處理這些 task ，並且而後發生的種種 trade-off。
Scalability  is the ability of a system, network, or process, to handle a growing amount of work in a capable manner or its ability to be enlarged to accommodate that growth
 Growth 可以從很多面向來看，但最重要相關的觀點用以來量測就是performance and availability
Performance (and latency)  is characterized by the amount of useful work accomplished by a computer system compared to the time and resources used</description>
    </item>
    
  </channel>
</rss>